{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalizeText(s):\n",
    "    \"\"\"\n",
    "    Ritorna testo minuscolo, senza punteggiatura, senza numeri e senza sequenze di apice seguite da spazio.\n",
    "    :param: s (string)\n",
    "    :return: string\n",
    "    \"\"\"\n",
    "    s = s.encode('utf-8', 'ignore').decode('utf-8')\n",
    "    \n",
    "    s = s.lower()\n",
    "    \n",
    "    # Rimuovo tutta la punteggiatura (tranne ') sostituendola con SPAZIO\n",
    "    chars = '[%s]+' % re.escape('!$&()\"*+,-./:;<=>?@[\\\\]^_`{|}~\\n\\t')\n",
    "    s = re.sub(chars, ' ', s)\n",
    "    \n",
    "    # Rimuovo tutti i numeri\n",
    "    s = re.sub(r'\\d+', ' ', s)\n",
    "    \n",
    "    # Aggiungo uno spazio dopo l'apice\n",
    "    s = re.sub(r\"(?<=\\')\", \" \", s)  # Usa lookbehind per aggiungere uno spazio dopo l'apice\n",
    "    \n",
    "    # Rimuovo doppi spazi\n",
    "    s = re.sub(r\"(\\s)+\", \" \", s)\n",
    "    \n",
    "    # Rimuovo spazi iniziali e finali\n",
    "    s = s.strip()\n",
    "    \n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcola_wer(riferimenti, predetti):\n",
    "    \"\"\"\n",
    "    Calcola WER (non nel modo standard), se vuoi quella std somma (I+D+S)/N\n",
    "    \"\"\"\n",
    "    # Legge il testo del file di predizione\n",
    "    with open(predetti, \"r\", encoding=\"utf-8\") as file:\n",
    "        testo = normalizeText(file.read())\n",
    "    \n",
    "    # Legge il testo del file di riferimento\n",
    "    with open(riferimenti, \"r\", encoding=\"utf-8\") as ref_file:\n",
    "        testo_riferimento = normalizeText(ref_file.read())\n",
    "    \n",
    "    # Calcola la Word Error Rate (WER) e ottiene i dettagli\n",
    "    dettagli = jiwer.compute_measures(testo_riferimento, testo)\n",
    "    \n",
    "    # Calcola il numero di parole nel testo di riferimento\n",
    "    num_parole = len(testo_riferimento.split())\n",
    "    \n",
    "    inserimenti = dettagli['insertions']\n",
    "    cancellazioni = dettagli['deletions']\n",
    "    sostituzioni = dettagli['substitutions']\n",
    "    wer = (inserimenti + cancellazioni + sostituzioni) / num_parole\n",
    "    \n",
    "    return wer, inserimenti, cancellazioni, sostituzioni, num_parole\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estrai_testo_xml(input_filename):\n",
    "    \"\"\"\n",
    "    Estrai trascrizioni da XML\n",
    "    \"\"\"\n",
    "    with open(input_filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        xml_content = file.read()\n",
    "\n",
    "    try:\n",
    "        # Parsing XML\n",
    "        root = ET.fromstring(xml_content)\n",
    "        print(\"XML caricato con successo.\")\n",
    "    except ET.ParseError:\n",
    "        print(input_filename)\n",
    "    except Exception as e:\n",
    "        print(input_filename)\n",
    "\n",
    "    parole = [token.get(\"data-text\") for token in root.findall(\".//span[@class='token pvText-container']\")]\n",
    "\n",
    "    frase = \" \".join(parole)\n",
    "\n",
    "    output_filename = os.path.splitext(input_filename)[0] + \"_output.txt\"\n",
    "\n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as output_file:\n",
    "        output_file.write(frase)\n",
    "        \n",
    "    return output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"ENG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = True\n",
    "if remove:\n",
    "    outfiles = []\n",
    "    directory_paths = [f\"/workspace/tirocinio/fine-tuning/TestSets/{lang}/ACS\", f\"/workspace/tirocinio/fine-tuning/TestSets/{lang}/AW_E2E\", f\"/workspace/tirocinio/fine-tuning/TestSets/{lang}/GCS\"]\n",
    "    for dir in directory_paths:\n",
    "        files = glob.glob(os.path.join(dir, \"*_output.txt\"))\n",
    "        for file in files:\n",
    "            os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfiles = []\n",
    "directory_paths = [f\"/workspace/tirocinio/fine-tuning/TestSets/{lang}/ACS\", f\"/workspace/tirocinio/fine-tuning/TestSets/{lang}/AW_E2E\", f\"/workspace/tirocinio/fine-tuning/TestSets/{lang}/GCS\"]\n",
    "for dir in directory_paths:\n",
    "    files = glob.glob(os.path.join(dir, \"*.txt\"))\n",
    "    for file in files:\n",
    "        outfile = estrai_testo_xml(file)\n",
    "        outfiles.append(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in directory_paths:\n",
    "    # Variabili per sommare i valori di WER e contare i file\n",
    "    somma_wer = 0\n",
    "    somma_inserimenti = 0\n",
    "    somma_cancellazioni = 0\n",
    "    somma_sostituzioni = 0\n",
    "    num_files = 0\n",
    "    parole_totali = 0\n",
    "    \n",
    "    for file_path in outfiles:\n",
    "        ref = os.path.join(f\"/workspace/tirocinio/fine-tuning/TestSets/{lang}/Ref\", os.path.basename(file_path).replace(\"_output.txt\", \".ref\"))\n",
    "        if file_path.startswith(dir):\n",
    "            wer_value, inserimenti, cancellazioni, sostituzioni, num_parole = calcola_wer(riferimenti=ref, predetti=file_path)\n",
    "            somma_wer += wer_value\n",
    "            somma_inserimenti += inserimenti\n",
    "            somma_cancellazioni += cancellazioni\n",
    "            somma_sostituzioni += sostituzioni\n",
    "            parole_totali += num_parole\n",
    "            num_files += 1\n",
    "\n",
    "    if num_files > 0:\n",
    "        #wer_media = somma_wer / num_files\n",
    "        wer_media = somma_wer / num_files\n",
    "        print(f\"Directory: {dir}\")\n",
    "        print(f\"  WER media: {wer_media:.4f}\")\n",
    "        print(f\"  Totale Inserimenti: {somma_inserimenti}\")\n",
    "        print(f\"  Totale Cancellazioni: {somma_cancellazioni}\")\n",
    "        print(f\"  Totale Sostituzioni: {somma_sostituzioni}\")\n",
    "        print(f\"  Totale Parole: {parole_totali}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"Nessun file trovato in {dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WER standard\n",
    "\n",
    "### WER ENG\n",
    "Directory: /workspace/tirocinio/fine-tuning/TestSets/ENG/ACS    \n",
    "  WER media: 0.0924  \n",
    "  Totale Inserimenti: 444  \n",
    "  Totale Cancellazioni: 181  \n",
    "  Totale Sostituzioni: 706  \n",
    "  Totale Parole: 13999  \n",
    "\n",
    "Directory: /workspace/tirocinio/fine-tuning/TestSets/ENG/AW_E2E   \n",
    "  WER media: 0.0756  \n",
    "  Totale Inserimenti: 196  \n",
    "  Totale Cancellazioni: 194  \n",
    "  Totale Sostituzioni: 718  \n",
    "  Totale Parole: 13999  \n",
    "\n",
    "Directory: /workspace/tirocinio/fine-tuning/TestSets/ENG/GCS  \n",
    "  WER media: 0.2573  \n",
    "  Totale Inserimenti: 358  \n",
    "  Totale Cancellazioni: 1661  \n",
    "  Totale Sostituzioni: 1668  \n",
    "  Totale Parole: 13999  \n",
    "\n",
    "\n",
    "### WER ITA\n",
    " \n",
    "Directory: /workspace/tirocinio/fine-tuning/TestSets/ITA/ACS  \n",
    "  WER media: 0.0928  \n",
    "  Totale Inserimenti: 753  \n",
    "  Totale Cancellazioni: 306  \n",
    "  Totale Sostituzioni: 601  \n",
    "  Totale Parole: 18309  \n",
    "\n",
    "Directory: /workspace/tirocinio/fine-tuning/TestSets/ITA/AW_E2E  \n",
    "  WER media: 0.1129  \n",
    "  Totale Inserimenti: 291  \n",
    "  Totale Cancellazioni: 895  \n",
    "  Totale Sostituzioni: 779  \n",
    "  Totale Parole: 18309  \n",
    "  \n",
    "Directory: /workspace/tirocinio/fine-tuning/TestSets/ITA/GCS  \n",
    "  WER media: 0.1802  \n",
    "  Totale Inserimenti: 274   \n",
    "  Totale Cancellazioni: 1508  \n",
    "  Totale Sostituzioni: 1505  \n",
    "  Totale Parole: 18309  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trascrittore NVIDIA\n",
    "Trascrivo i file forniti (prima li ho tagliati in modo che siano <6 minuti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"ITA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio(file_path, segment_duration=4):\n",
    "    audio = AudioSegment.from_wav(file_path)\n",
    "    \n",
    "    # Ottieni la durata in millisecondi\n",
    "    duration_ms = len(audio)\n",
    "    duration_min = duration_ms / (1000 * 60)\n",
    "    print(f\"Durata totale: {duration_min:.2f} minuti\")\n",
    "\n",
    "    # Calcola il numero di segmenti\n",
    "    segment_duration_ms = segment_duration * 60 * 1000  # 4 minuti in millisecondi\n",
    "    num_segments = (duration_ms // segment_duration_ms) + (1 if duration_ms % segment_duration_ms != 0 else 0)\n",
    "\n",
    "    output_folder = f\"/workspace/tirocinio/fine-tuning/TestSets/{lang}/short_audio\"\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_time = i * segment_duration_ms\n",
    "        end_time = start_time + segment_duration_ms\n",
    "        if end_time > duration_ms:\n",
    "            end_time = duration_ms\n",
    "        \n",
    "        # Estrai il segmento\n",
    "        segment = audio[start_time:end_time]\n",
    "        \n",
    "        # Salva il segmento\n",
    "        segment.export(os.path.join(output_folder, f\"{base_name}_{i + 1}.wav\"), format=\"wav\")\n",
    "        print(f\"Segmento {i + 1} salvato.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divido i file audio\n",
    "dir = f\"/workspace/tirocinio/fine-tuning/TestSets/{lang}/Audio\"\n",
    "for nome_file in os.listdir(dir):\n",
    "        if nome_file.endswith(\".wav\"):\n",
    "            split_audio(os.path.join(dir,nome_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "asr_model = nemo_asr.models.EncDecHybridRNNTCTCBPEModel.from_pretrained(model_name=\"stt_multilingual_fastconformer_hybrid_large_pc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trascrivo i file\n",
    "audiodir = f\"TestSets/{lang}/short_audio\"\n",
    "transcript_dir = f\"/workspace/tirocinio/fine-tuning/TestSets/{lang}/NVIDIA\"\n",
    "files = glob.glob(os.path.join(audiodir, \"*.wav\"))\n",
    "\n",
    "i = 0\n",
    "for file in files:\n",
    "    transcript_file = os.path.join(transcript_dir, os.path.basename(file).replace(\".wav\", \".txt\"))\n",
    "    print(f\"Trascrivo il file: {file}\")\n",
    "    transcript = asr_model.transcribe([file])\n",
    "    with open(transcript_file, \"w\", encoding='utf-8') as outfile:\n",
    "        testo = transcript[0][0]\n",
    "        outfile.write(testo)\n",
    "\n",
    "    dest = f\"TestSets/{lang}/short_audio/Done/{os.path.basename(file)}\"\n",
    "\n",
    "    if os.path.exists(dest):\n",
    "        os.remove(dest)\n",
    "\n",
    "    shutil.move(file, dest)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Unisce i file trascritti con nome comune dando il path della cartella\n",
    "def join_predictions(dir):\n",
    "    \"\"\"\n",
    "    Unisce i file trascritti con nome comune\n",
    "    \"\"\"\n",
    "    gruppi_file = defaultdict(list)\n",
    "    predictions = []\n",
    "\n",
    "    # Prendo tutti i file trascritti e li raggruppo per il prefisso del nome senza _n\n",
    "    files = glob.glob(os.path.join(dir, '*.txt'))\n",
    "    for file in files:\n",
    "        nome_file = os.path.basename(file)\n",
    "        nome_base = \"_\".join(nome_file.split(\"_\")[:-1])\n",
    "        gruppi_file[nome_base].append(nome_file)\n",
    "\n",
    "    # Per ogni gruppo di file con lo stesso prefisso\n",
    "    for nome_base, file_list in gruppi_file.items():\n",
    "        file_list.sort()\n",
    "        \n",
    "        # Apro il nuovo file che conterrÃ  tutte le trascrizioni di quel gruppo\n",
    "        nome_output = os.path.join(dir, f\"{nome_base}.txt\")\n",
    "        with open(nome_output, 'w', encoding='utf-8') as file_output:\n",
    "            for nome_file in file_list:\n",
    "                percorso_file = os.path.join(dir, nome_file)\n",
    "                \n",
    "                # Leggo il contenuto di ogni file del gruppo e lo scrivo\n",
    "                with open(percorso_file, 'r', encoding='utf-8') as file_input:\n",
    "                    contenuto = file_input.read()\n",
    "                    file_output.write(contenuto + \" \")\n",
    "                \n",
    "                # Una volta trascritto il file lo sposto nella cartella {dir}/Done\n",
    "                destination_path = os.path.join(dir, \"Done\", nome_file)\n",
    "                if os.path.exists(destination_path):\n",
    "                    os.remove(destination_path)\n",
    "\n",
    "                shutil.move(percorso_file, destination_path)\n",
    "        predictions.append(nome_output)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_files(predictions, references):\n",
    "    \"\"\"\n",
    "    Accoppia ogni prediction alla propria reference\n",
    "    \"\"\"\n",
    "    # Crea dei dizionari per mappare il nome del file senza estensione con il percorso completo\n",
    "    pred_dict = {os.path.splitext(os.path.basename(p))[0]: p for p in predictions}\n",
    "    ref_dict = {os.path.splitext(os.path.basename(r))[0]: r for r in references}\n",
    "\n",
    "    # Trova le coppie con lo stesso nome e crea una lista di tuple\n",
    "    paired_files = [(pred_dict[name], ref_dict[name]) for name in pred_dict if name in ref_dict]\n",
    "\n",
    "    return paired_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisco variabili\n",
    "dir = f\"/workspace/tirocinio/fine-tuning/TestSets/{lang}/NVIDIA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino i file output.txt (non serve sempre)\n",
    "for nome_file in os.listdir(dir):\n",
    "    if nome_file.endswith(\"output.txt\"):\n",
    "        os.remove(os.path.join(dir, nome_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join delle trascrizioni e muovo i file in transcripted\n",
    "outfiles = join_predictions(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = glob.glob(os.path.join(f\"/workspace/tirocinio/fine-tuning/TestSets/{lang}/Ref\", '*.ref'))   \n",
    "pairs = pair_files(predictions=outfiles, references=ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pres:\")\n",
    "for p in outfiles:\n",
    "    print(f\"\\t{p}\")\n",
    "\n",
    "print(\"ref\")\n",
    "for p in ref:\n",
    "    print(f\"\\t{p}\")\n",
    "\n",
    "print(\"Pairs\")\n",
    "for p in pairs:\n",
    "    print(f\"\\t{p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabili per sommare i valori di WER e contare i file\n",
    "somma_wer = 0\n",
    "somma_inserimenti = 0\n",
    "somma_cancellazioni = 0\n",
    "somma_sostituzioni = 0\n",
    "num_files = 0\n",
    "parole_totali = 0\n",
    "\n",
    "for pred, reff  in pairs:\n",
    "    wer_value, inserimenti, cancellazioni, sostituzioni, num_parole = calcola_wer(riferimenti=reff, predetti=pred)\n",
    "    print(f\"{pred}: {wer_value}\")\n",
    "    somma_wer += wer_value\n",
    "    somma_inserimenti += inserimenti\n",
    "    somma_cancellazioni += cancellazioni\n",
    "    somma_sostituzioni += sostituzioni\n",
    "    parole_totali += num_parole\n",
    "    num_files += 1\n",
    "\n",
    "if num_files > 0:\n",
    "    wer_media = somma_wer / num_files\n",
    "    print(f\"Directory: {dir}\")\n",
    "    print(f\"  WER media: {wer_media:.4f}\")\n",
    "    print(f\"  Totale Inserimenti: {somma_inserimenti}\")\n",
    "    print(f\"  Totale Cancellazioni: {somma_cancellazioni}\")\n",
    "    print(f\"  Totale Sostituzioni: {somma_sostituzioni}\")\n",
    "    print(f\"  Totale Parole: {parole_totali}\")\n",
    "    print()\n",
    "else:\n",
    "    print(f\"Nessun file trovato in {dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WER standard ENG\n",
    "Directory: /workspace/tirocinio/fine-tuning/TestSets/ENG/NVIDIA  \n",
    "  WER media: 0.1045  \n",
    "  Totale Inserimenti: 452  \n",
    "  Totale Cancellazioni: 313  \n",
    "  Totale Sostituzioni: 1037  \n",
    "  Totale Parole: 16706  \n",
    "\n",
    "# WER standard ITA\n",
    "Directory: /workspace/tirocinio/fine-tuning/TestSets/ITA/NVIDIA  \n",
    "  WER media: 0.1994  \n",
    "  Totale Inserimenti: 330  \n",
    "  Totale Cancellazioni: 1676  \n",
    "  Totale Sostituzioni: 1338  \n",
    "  Totale Parole: 18309  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
